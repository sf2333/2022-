{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#设置print格式\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "np.set_printoptions(threshold=20)\n",
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "pd.set_option('display.max_rows', 500)  #最大行数\n",
    "pd.set_option('display.max_columns', 500)    #最大列数\n",
    "pd.set_option('display.width', 4000)        #页面宽度\n",
    "\n",
    "def convert_num(x, fill=None):\n",
    "    x = str(x)\n",
    "    try:\n",
    "        res = Decimal(x)/ Decimal(10000)\n",
    "    except Exception:\n",
    "        res = fill if fill else np.NaN\n",
    "    return res\n",
    "\n",
    "#数据路径\n",
    "import os\n",
    "url_base = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#引入数据\n",
    "# /CSE-CIC-IDS2018 all Data\n",
    "url_data = f\"{url_base}/all.csv\"\n",
    "\n",
    "# info data (column names, col types)\n",
    "url_info = f\"{url_base}/all_names.names\"\n",
    "\n",
    "# Import info data\n",
    "df_info = pd.read_csv(url_info, sep=\":\", skiprows=1, index_col=False, names=[\"colname\", \"type\"])\n",
    "\n",
    "colnames = df_info.colname.values\n",
    "coltypes = np.where(df_info[\"type\"].str.contains(\"continuous\"), \"float\", \"str\")\n",
    "# print(df_info)\n",
    "\n",
    "# Import data\n",
    "df = pd.read_csv(url_data, names=colnames, index_col=False, dtype=dict(zip(colnames, coltypes)))\n",
    "# print(df)\n",
    "\n",
    "# Dumminize\n",
    "X = pd.get_dummies(df.iloc[:,:-1]).values\n",
    "# print(X)\n",
    "# X1 = pd.get_dummies(df.iloc[:,:-1])\n",
    "# print(X1)\n",
    "\n",
    "for x1 in X:\n",
    "    if np.isinf(x1).any():\n",
    "        print(x1)\n",
    "        for i in range(len(x1)):\n",
    "            if np.isinf(x1[i]):\n",
    "                print(i)\n",
    "        # print(np.isinf(x1).any())\n",
    "\n",
    "# Create Traget Flag\n",
    "# Anomaly data when status is normal, Otherwise, Not anomaly.\n",
    "y = np.where(df.Label == \"BENIGN\", 1, 0)\n",
    "print(y)\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(524284, 78)\n",
      "(524284, 2)\n",
      "[[ 0.000  1.000]\n",
      " [ 0.000  1.000]\n",
      " [ 0.000  1.000]\n",
      " ...\n",
      " [ 0.000  1.000]\n",
      " [ 0.000  1.000]\n",
      " [ 1.000  0.000]]\n"
     ]
    }
   ],
   "source": [
    "#数据预处理\n",
    "#标准化函数\n",
    "scaler = StandardScaler()\n",
    "X_soc = X_train\n",
    "X_soc_test = X_test\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "print(X_train.shape)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = np.reshape(X_train,[-1,78,1])\n",
    "X_test = np.reshape(X_test,[-1,78,1])\n",
    "\n",
    "def dense_to_one_hot(labels_dense, num_classes):\n",
    "    \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset+labels_dense.ravel()] = 1\n",
    "    return labels_one_hot\n",
    " \n",
    "num_classes  = 2\n",
    "one_hot_train = dense_to_one_hot(y_train,num_classes)\n",
    "one_hot_test = dense_to_one_hot(y_test,num_classes)\n",
    "print(one_hot_train.shape)\n",
    "print(one_hot_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tflearn\\initializations.py:165: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tflearn\\layers\\core.py:247: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#建立模型结构，就是几个全连接\n",
    "#import tflearn\n",
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_1d, max_pool_1d,global_max_pool\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "# Building convolutional network\n",
    "network = input_data(shape=[None,78,1], name='input')\n",
    "# network = fully_connected(network, 64, activation='tanh')\n",
    "network = fully_connected(network, 32, activation='tanh')\n",
    "network = fully_connected(network, 10, activation='tanh')\n",
    "network = dropout(network, 0.5)\n",
    "\n",
    "network = fully_connected(network, 2, activation='softmax')\n",
    "network = regression(network, optimizer='adam', learning_rate=0.01,\n",
    "                     loss='categorical_crossentropy', name='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8191  | total loss: \u001b[1m\u001b[32m0.05029\u001b[0m\u001b[0m | time: 27.956s\n",
      "| Adam | epoch: 001 | loss: 0.05029 - acc: 0.9924 -- iter: 524224/524284\n",
      "Training Step: 8192  | total loss: \u001b[1m\u001b[32m0.05268\u001b[0m\u001b[0m | time: 34.720s\n",
      "| Adam | epoch: 001 | loss: 0.05268 - acc: 0.9916 | val_loss: 0.03165 - val_acc: 0.9931 -- iter: 524284/524284\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model = tflearn.DNN(network, tensorboard_verbose=0)\n",
    "model.fit({'input': X_train}, {'target': one_hot_train}, n_epoch=1,\n",
    "          validation_set=({'input': X_test}, {'target': one_hot_test}),\n",
    "          show_metric=True, run_id='cnn_demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DH\\AppData\\Local\\Temp/ipykernel_18584/196934816.py:8: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#提取tflearn生成会话中的变量\n",
    "\n",
    "input_ = model.session.graph.get_tensor_by_name('input/X:0')\n",
    "output_ = model.session.graph.get_tensor_by_name('FullyConnected_3/BiasAdd:0')\n",
    "softmax_ = model.session.graph.get_tensor_by_name('FullyConnected_3/Softmax:0')\n",
    "target_ =model.session.graph.get_tensor_by_name('target/Y:0')\n",
    "#构造损失函数\n",
    "loss_ = tf.nn.softmax_cross_entropy_with_logits(logits=softmax_, labels=target_)#output_\n",
    "#loss梯度\n",
    "gradw, = tf.gradients(loss_,input_)\n",
    "#向前梯度\n",
    "derivative, = tf.gradients(output_[0,1], input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将生成的对抗样本合法化\n",
    "def x1_transform(x1):\n",
    "    x1 = scaler.inverse_transform(x1)\n",
    "    x1x = []\n",
    "    x1x1 = np.int32(x1[0][0:17])\n",
    "    x1x  =  np.append(x1x,x1x1)\n",
    "    x1x1 = np.float32(x1[0][17:24])\n",
    "    x1x  =  np.append(x1x,x1x1)\n",
    "    x1x1 = np.int32(x1[0][24:26])\n",
    "    x1x  =  np.append(x1x,x1x1)\n",
    "    x1x1 = np.float32(x1[0][26:34])\n",
    "    x1x  =  np.append(x1x,x1x1)\n",
    "    x1x1 = np.int32(np.rint(x1[0][34:78]))\n",
    "    x1x  =  np.append(x1x,x1x1)\n",
    "    x1x = np.around(x1x, decimals=2)\n",
    "    x1 = scaler.transform(np.reshape(x1x,[1,78]))\n",
    "    return x1,x1x\n",
    "    #x1是归一化的，x1x才是生成对抗样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Deepfool(sample_n): \n",
    "    ok = True\n",
    "    targets = [0,1]\n",
    "    sample = np.array(X_train[sample_n:sample_n+1])\n",
    "    x1 = np.reshape(sample,[1,78])\n",
    "    #最大最小值\n",
    "    x1_d = np.min(X_soc,axis=0)\n",
    "    x1_u = np.max(X_soc,axis=0)\n",
    "    \n",
    "    #初始参数\n",
    "    r_tot = np.zeros([1,78])\n",
    "    c = np.zeros(x1.shape[1]-34)\n",
    "\n",
    "    for epoch in range(1000):\n",
    "        #计算梯度\n",
    "        x_ = np.reshape(x1,[-1,78,1])\n",
    "        y1,_,gg_ = model.session.run([softmax_,loss_,gradw],{input_:x_,target_:[targets]})\n",
    "\n",
    "        if np.argmax(y1) == np.argmax(targets):\n",
    "            #如果生成了对抗样本。\n",
    "            x1,x1x = x1_transform(x1)\n",
    "            #将生成的对抗样本合法化\n",
    "            x_ = np.reshape(x1,[-1,78,1])\n",
    "            y1,_,gg_ = model.session.run([softmax_,loss_,gradw],{input_:x_,target_:[targets]})\n",
    "            if np.argmax(y1) == np.argmax(targets):\n",
    "                #如果生成的对抗样本合法化后依然是对抗样本。\n",
    "                d_d = x1x-X_soc_test[sample_n]\n",
    "                L0 = np.linalg.norm(d_d,ord=0)\n",
    "                print('L0=',L0)\n",
    "                break#生成成功退出循环\n",
    "\n",
    "        #用deepflow的方式计算更改样本\n",
    "        gg=[]\n",
    "        gg = np.append(gg_[0][0:34],c)\n",
    "        gg = np.reshape(gg,[1,78])\n",
    "        pert = np.abs(y1[0][np.argmax(targets)])/np.linalg.norm(gg)\n",
    "        r_i = (pert+1e-8) * gg/np.linalg.norm(gg)\n",
    "        r_tot = np.float32(r_tot+r_i)\n",
    "\n",
    "        x1 = x1-1.1*r_tot\n",
    "        \n",
    "\n",
    "        #对x1的特征进行一个限制，限制在所有样本最大值内。\n",
    "        x1 = scaler.inverse_transform(x1)\n",
    "        x1x = []\n",
    "        for i in range(78):\n",
    "            x1x1 = np.float32(np.clip(x1[0][i:i+1],x1_d[i],x1_u[i]))\n",
    "            x1x  =  np.append(x1x,x1x1)\n",
    "        x1  = np.reshape(x1x,[1,78])\n",
    "        x1 = scaler.transform(np.reshape(x1x,[1,78]))\n",
    "\n",
    "    if epoch == 999:\n",
    "        print('对抗样本生成失败，迭代次数 =',epoch)\n",
    "        return False\n",
    "    else:\n",
    "        print('对抗样本生成成功，迭代次数 =',epoch,' , L0 =',L0)\n",
    "        return x1x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#实现saliency_map\n",
    "def saliency_map(derivative, mask):\n",
    "        mask = np.reshape(mask,[78])\n",
    "        #print('mask',mask[0],mask[0,21,0])\n",
    "        alphas = derivative * mask\n",
    "        \n",
    "        # pixel influence on sum of residual classes\n",
    "        betas = -np.ones_like(alphas)\n",
    "        \n",
    "        sal_map = np.abs(alphas) * np.abs(betas) * np.sign(alphas * betas)\n",
    "        # find optimal pixel & direction of perturbation\n",
    "        #print(sal_map*1000)\n",
    "        ''''''\n",
    "        for sa in range(len(sal_map)):\n",
    "            if mask[sa] ==0:\n",
    "                sal_map[sa] = float(\"inf\")#10000#\n",
    "                \n",
    "        idx = np.argmin(sal_map)\n",
    "        #print('sal_map=', sal_map)\n",
    "        #转换成(p1,p2)格式      \n",
    "        idx = np.unravel_index(idx, mask.shape)\n",
    "        pix_sign = np.sign(alphas)[idx]\n",
    "        \n",
    "        return idx, pix_sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JSMA(sample_n):\n",
    "    ok = True\n",
    "    targets = [0,1]\n",
    "    sample = np.array(X_train[sample_n:sample_n+1])\n",
    "    x1 = np.reshape(sample,[1,78])\n",
    "\n",
    "    mask = np.ones_like(x1)\n",
    "    #最大最小值\n",
    "    x1_d = np.min(X_soc,axis=0)\n",
    "    x1_u = np.max(X_soc,axis=0)\n",
    "    #定义边界\n",
    "    max_=scaler.transform([x1_u])\n",
    "    min_=scaler.transform([x1_d])\n",
    "    max_ = np.reshape(max_,[78])\n",
    "    min_ = np.reshape(min_,[78])\n",
    "\n",
    "    c = np.zeros(x1.shape[1]-34)\n",
    "    L0 = 0\n",
    "\n",
    "    for epoch in range(1000):\n",
    "\n",
    "        x_ = np.reshape(x1,[-1,78,1])\n",
    "        y1,loss1,gg_,d = model.session.run([softmax_,loss_,gradw,derivative],{input_:x_,target_:[targets]})\n",
    "        \n",
    "        if np.argmax(y1) == np.argmax(targets):\n",
    "            x1,x1x = x1_transform(x1)\n",
    "            #将生成的对抗样本合法化\n",
    "\n",
    "            x1 = scaler.transform(np.reshape(x1x,[1,78]))\n",
    "            x_ = np.reshape(x1,[-1,78,1])\n",
    "            y1,loss1,gg_ = model.session.run([softmax_,loss_,gradw],{input_:x_,target_:[targets]})\n",
    "\n",
    "            if np.argmax(y1) == np.argmax(targets):\n",
    "                #如果生成的对抗样本合法化后依然是对抗样本。\n",
    "                d_d = x1x-X_soc_test[sample_n]\n",
    "                L0 = np.linalg.norm(d_d,ord=0)\n",
    "                print('L0=',L0)\n",
    "                break#生成成功退出循环\n",
    "    \n",
    "    \n",
    "        #JSMA更新样本\n",
    "        gg=[]\n",
    "        gg = np.append(d[0][0:34],c)\n",
    "        idx, pix_sign=saliency_map(gg, mask)\n",
    "        x1 = np.reshape(x1,[78])\n",
    "        x1[idx]+=pix_sign * 0.1 * (max_[idx] - min_[idx]) \n",
    "        \n",
    "        #达到极限的点不再参与更新\n",
    "        if (x1[idx]<=min_[idx]) or (x1[idx]>=max_[idx]):\n",
    "            mask[0][idx]=0\n",
    "            x1[idx]=np.clip(x1[idx], min_[idx], max_[idx])\n",
    "        \n",
    "        #对x1的特征进行一个限制，限制在所有样本最大值内。\n",
    "        x1 = np.reshape(x1,[1,78])\n",
    "        x1 = scaler.inverse_transform(x1)\n",
    "        x1x = []\n",
    "        for i in range(78):\n",
    "            x1x1 = np.float32(np.clip(x1[0][i:i+1],x1_d[i],x1_u[i]))\n",
    "            x1x  =  np.append(x1x,x1x1)\n",
    "        x1  = np.reshape(x1x,[1,78])\n",
    "        x1 = scaler.transform(np.reshape(x1x,[1,78]))\n",
    "\n",
    "    x1 = scaler.inverse_transform(x1)\n",
    "    if epoch == 999:\n",
    "        print('对抗样本生成失败，迭代次数 =',epoch)\n",
    "        return False\n",
    "    else:\n",
    "        print('对抗样本生成成功，迭代次数 =',epoch,' , L0 =',L0)\n",
    "        return x1x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive [     0      2      5 ... 524280 524282 524283] 379722\n",
      "negative [     1      3      4 ... 524273 524279 524281] 144562\n",
      "L0= 57.0\n",
      "对抗样本生成成功，迭代次数 = 1  , L0 = 57.0\n",
      "[ 0.000  18704.000  17.000 ...  0.000  0.000  0.000]\n"
     ]
    }
   ],
   "source": [
    "#数据特征的前34是数值，只用改变前34个特征。\n",
    "positive = np.int32(np.where(y_train==1)).reshape(-1)#正样本位置\n",
    "negative = np.int32(np.where(y_train==0)).reshape(-1)#负样本位置\n",
    "print('positive',positive,len(positive))        \n",
    "print('negative',negative,len(negative))\n",
    "#输入负样本的位置，生成对抗样本。不是所有样本都能生成对抗样本，大部分可以。\n",
    "aes = negative[100]\n",
    "ae = Deepfool(aes)\n",
    "print(ae)\n",
    "# ae = JSMA(aes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "0.0 ,18704.0 ,17.0 ,119999984.0 ,1.0 ,54115.0 ,94248.0 ,12529669.0 ,16668.0 ,0.0 ,2720.0 ,4850.0 ,7827.0 ,533.0 ,3340.0 ,0.0 ,-13.0 ,0.0 ,120000000.0 ,102562944.0 ,120000000.0 ,70756264.0 ,0.0 ,25408514.0 ,119999999.0 ,119999999.0 ,120000000.0 ,56220776.0 ,120000000.0 ,77722072.0 ,1.0 ,0.0 ,0.0 ,0.0 ,40.0 ,20.0 ,20408.0 ,20408.0 ,0.0 ,6.0 ,2.0 ,3.0 ,12.0 ,0.0 ,0.0 ,0.0 ,1.0 ,0.0 ,0.0 ,0.0 ,0.0 ,1.0 ,3.0 ,0.0 ,6.0 ,40.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,1.0 ,0.0 ,1.0 ,6.0 ,29200.0 ,0.0 ,0.0 ,40.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,"
     ]
    }
   ],
   "source": [
    "print(len(ae))\n",
    "for i in ae:\n",
    "    print(i,',',end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "60368.0 ,53.0 ,17.0 ,23695.0 ,1.0 ,1.0 ,43.0 ,139.0 ,43.0 ,43.0 ,43.0 ,0.0 ,139.0 ,139.0 ,139.0 ,0.0 ,23695.0 ,0.0 ,23695.0 ,23695.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,20.0 ,20.0 ,42.20299641 ,42.20299641 ,43.0 ,139.0 ,75.0 ,55.42562584 ,3072.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,1.0 ,112.5 ,43.0 ,139.0 ,20.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,1.0 ,43.0 ,1.0 ,139.0 ,-1.0 ,-1.0 ,0.0 ,20.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,"
     ]
    }
   ],
   "source": [
    "print(len(X_soc_test[negative[0]]))\n",
    "for i in X_soc_test[negative[0]]:\n",
    "    print(i,',',end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f7471677c3eccb4f7f87eeadc33cee708012785cef252896dc4f780e13ed304"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 470,
   "position": {
    "height": "40px",
    "left": "1195.66px",
    "right": "20px",
    "top": "-16px",
    "width": "664px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
