{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIC2018 100%Data Evaluation\n",
    "- Import CIC2018 100%data from network and check performance of anomaly detection.\n",
    "- To execute this notebook, need python(3.6), tensorflow, pandas, numpy, sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from dagmm import DAGMM\n",
    "\n",
    "#数据路径\n",
    "import os\n",
    "url_base = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#引入数据\n",
    "# /CSE-CIC-IDS2018 all Data\n",
    "url_data = f\"{url_base}/all.csv\"\n",
    "\n",
    "# info data (column names, col types)\n",
    "url_info = f\"{url_base}/all_names.names\"\n",
    "\n",
    "# Import info data\n",
    "df_info = pd.read_csv(url_info, sep=\":\", skiprows=1, index_col=False, names=[\"colname\", \"type\"])\n",
    "\n",
    "colnames = df_info.colname.values\n",
    "coltypes = np.where(df_info[\"type\"].str.contains(\"continuous\"), \"float\", \"str\")\n",
    "# print(df_info)\n",
    "\n",
    "# Import data\n",
    "df = pd.read_csv(url_data, names=colnames, index_col=False, dtype=dict(zip(colnames, coltypes)))\n",
    "# print(df)\n",
    "\n",
    "# Dumminize\n",
    "X = pd.get_dummies(df.iloc[:,:-1]).values\n",
    "# print(X)\n",
    "# X1 = pd.get_dummies(df.iloc[:,:-1])\n",
    "# print(X1)\n",
    "\n",
    "for x1 in X:\n",
    "    if np.isinf(x1).any():\n",
    "        print(x1)\n",
    "        for i in range(len(x1)):\n",
    "            if np.isinf(x1[i]):\n",
    "                print(i)\n",
    "        # print(np.isinf(x1).any())\n",
    "\n",
    "# Create Traget Flag\n",
    "# Anomaly data when status is normal, Otherwise, Not anomaly.\n",
    "y = np.where(df.Label == \"BENIGN\", 1, 0) # 1是normal，0是Bad\n",
    "print(y)\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=123)\n",
    "X_train, y_train = X_train[y_train == 0], y_train[y_train == 0]     # 用恶意样本训练\n",
    "# print(X_train)\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Data to DAGMM Model\n",
    "next points are different from original paper:\n",
    "- $\\lambda_2$ is set to 0.0001 (paper: 0.005)\n",
    "- Add small value($10^{-6}$) to diagonal elements of GMM covariance (paper: no additional value)\n",
    "\n",
    "Standard Scaler is applied to input data (This DAGMM implementation default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DAGMM(\n",
    "    comp_hiddens=[60, 30, 10, 1], comp_activation=tf.nn.tanh,\n",
    "    est_hiddens=[10, 4], est_dropout_ratio=0.5, est_activation=tf.nn.tanh,\n",
    "    learning_rate=0.0001, epoch_size=2000, minibatch_size=1024, random_seed=1111\n",
    ")\n",
    "\n",
    "# epoch_size=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From H:\\Users\\DH\\桌面\\2022大创\\code\\Adversarial Examples attack and defense systems\\detection model\\dagmm\\dagmm.py:108: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From H:\\Users\\DH\\桌面\\2022大创\\code\\Adversarial Examples attack and defense systems\\detection model\\dagmm\\dagmm.py:112: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From H:\\Users\\DH\\桌面\\2022大创\\code\\Adversarial Examples attack and defense systems\\detection model\\dagmm\\compression_net.py:107: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From H:\\Users\\DH\\桌面\\2022大创\\code\\Adversarial Examples attack and defense systems\\detection model\\dagmm\\compression_net.py:38: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From H:\\Users\\DH\\桌面\\2022大创\\code\\Adversarial Examples attack and defense systems\\detection model\\dagmm\\estimation_net.py:52: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From H:\\Users\\DH\\桌面\\2022大创\\code\\Adversarial Examples attack and defense systems\\detection model\\dagmm\\gmm.py:52: The name tf.diag is deprecated. Please use tf.linalg.tensor_diag instead.\n",
      "\n",
      "WARNING:tensorflow:From H:\\Users\\DH\\桌面\\2022大创\\code\\Adversarial Examples attack and defense systems\\detection model\\dagmm\\gmm.py:53: The name tf.cholesky is deprecated. Please use tf.linalg.cholesky instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:2403: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From H:\\Users\\DH\\桌面\\2022大创\\code\\Adversarial Examples attack and defense systems\\detection model\\dagmm\\dagmm.py:130: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      " epoch 100/2000 : loss = 21.973\n",
      " epoch 200/2000 : loss = 17.978\n",
      " epoch 300/2000 : loss = 15.635\n",
      " epoch 400/2000 : loss = 14.513\n",
      " epoch 500/2000 : loss = 13.775\n",
      " epoch 600/2000 : loss = 12.954\n",
      " epoch 700/2000 : loss = 12.383\n",
      " epoch 800/2000 : loss = 12.126\n",
      " epoch 900/2000 : loss = 10.403\n",
      " epoch 1000/2000 : loss = 9.283\n",
      " epoch 1100/2000 : loss = 8.436\n",
      " epoch 1200/2000 : loss = 7.680\n",
      " epoch 1300/2000 : loss = 7.026\n",
      " epoch 1400/2000 : loss = 6.472\n",
      " epoch 1500/2000 : loss = 6.044\n",
      " epoch 1600/2000 : loss = 5.704\n",
      " epoch 1700/2000 : loss = 5.440\n",
      " epoch 1800/2000 : loss = 5.221\n",
      " epoch 1900/2000 : loss = 5.119\n",
      " epoch 2000/2000 : loss = 4.920\n",
      "WARNING:tensorflow:From H:\\Users\\DH\\桌面\\2022大创\\code\\Adversarial Examples attack and defense systems\\detection model\\dagmm\\dagmm.py:166: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply model to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive [     0      1      2 ... 524280 524281 524282] 379923\n",
      "negative [     3      5      8 ... 524269 524279 524283] 144361\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "positive = np.int32(np.where(y_test==1)).reshape(-1)#正样本位置\n",
    "negative = np.int32(np.where(y_test==0)).reshape(-1)#负样本位置\n",
    "print('positive',positive,len(positive))        \n",
    "print('negative',negative,len(negative))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy thleshold to detect anomaly : 8.989\n"
     ]
    }
   ],
   "source": [
    "# Energy thleshold to detect anomaly = 30% percentile of energies\n",
    "# 初始阈值可随意设置，通过对比预测的 精度、回归度以及 Ｆ１分数来逐步调整阈值，数值越大说明越异常\n",
    "anomaly_energy_threshold = np.percentile(y_pred, 35)\n",
    "print(f\"Energy thleshold to detect anomaly : {anomaly_energy_threshold:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Energy thleshold to detect anomaly = 60% percentile of energies\n",
    "# anomaly_energy_threshold = np.percentile(y_pred, 60)\n",
    "# print(f\"Energy thleshold to detect anomaly : {anomaly_energy_threshold:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect anomalies from test data\n",
    "y_pred_flag = np.where(y_pred >= anomaly_energy_threshold, 1, 0) # 1是normal，0是Bad，因为模型是用恶意样本训练，数值超过阈值反而正常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Precision = 0.998\n",
      " Recall    = 0.895\n",
      " F1-Score  = 0.944\n"
     ]
    }
   ],
   "source": [
    "prec, recall, fscore, _ = precision_recall_fscore_support(y_test, y_pred_flag, average=\"binary\")\n",
    "print(f\" Precision = {prec:.3f}\")\n",
    "print(f\" Recall    = {recall:.3f}\")\n",
    "print(f\" F1-Score  = {fscore:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Adversarial Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 复制过来的结果\n",
    "\n",
    "#原始恶意样本\n",
    "se = [57420.0 ,1718.0 ,6.0 ,43.0 ,1.0 ,1.0 ,0.0 ,6.0 ,0.0 ,0.0 ,0.0 ,0.0 ,6.0 ,6.0 ,6.0 ,0.0 ,43.0 ,0.0 ,43.0 ,43.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,40.0 ,20.0 ,23255.81395 ,23255.81395 ,0.0 ,6.0 ,2.0 ,3.464101615 ,12.0 ,0.0 ,0.0 ,0.0 ,1.0 ,0.0 ,0.0 ,0.0 ,0.0 ,1.0 ,3.0 ,0.0 ,6.0 ,40.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,1.0 ,0.0 ,1.0 ,6.0 ,29200.0 ,0.0 ,0.0 ,40.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0]\n",
    "\n",
    "# 由DeepFool白盒攻击算法生成的恶意对抗样本\n",
    "deepfool_ae = [65535.0 ,0.0 ,7.64 ,7907271.5 ,79.33 ,1674.26 ,3000.83 ,331326.97 ,376.95 ,0.0 ,64.42 ,111.8 ,232.84 ,11.66 ,129.99 ,0.0 ,-13.0 ,0.0 ,4333376.5 ,2078429.0 ,5820347.0 ,1387770.62 ,0.0 ,3090121.5 ,3410977.25 ,1358718.38 ,1473928.0 ,183327.69 ,1060969.5 ,1546550.5 ,0.02 ,0.0 ,0.0 ,0.0 ,1799528.0 ,390757.16 ,131820.67 ,0.0 ,0.0 ,111.86 ,1.15 ,0.0 ,0.0 ,0.0 ,0.02 ,0.0 ,0.86 ,0.0 ,0.06 ,0.0 ,0.0 ,0.69 ,0.0 ,66.03 ,122.1 ,1784553.75 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,84.91 ,3007.71 ,1677.15 ,326482.81 ,32786.21 ,6592.64 ,0.0 ,60.0 ,51610.84 ,5918.59 ,24319.35 ,12805.21 ,1018882.62 ,0.0 ,1241427.5 ,844242.06]\n",
    "\n",
    "# 由JSMA白盒攻击算法生成的恶意对抗样本\n",
    "jsmas_ae = [65535.0 ,65534.0 ,12.8 ,43.0 ,1.0 ,1.0 ,0.0 ,6.0 ,0.0 ,0.0 ,0.0 ,0.0 ,6.0 ,6.0 ,6.0 ,0.0 ,43.0 ,0.0 ,43.0 ,43.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,-0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,40.0 ,20.0 ,23255.81 ,23255.81 ,0.0 ,6.0 ,2.0 ,3.46 ,12.0 ,0.0 ,0.0 ,0.0 ,1.0 ,0.0 ,0.0 ,0.0 ,0.0 ,1.0 ,3.0 ,0.0 ,6.0 ,40.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,1.0 ,0.0 ,1.0 ,6.0 ,29200.0 ,0.0 ,0.0 ,40.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0]\n",
    "\n",
    "#由GAN训练恶意对抗样本生成的恶意对抗样本\n",
    "gan_ae = [65467.08, 0.0, 17.0, 37.07, 1.0, 0.0, 0.0, 0.0, 0.0, 26.93, 0.59, 0.0, 30.89, 62.34, 23.96, 0.0, -13.0, 0.0, -5.85, -13.0, 0.0, 0.0, 0.0, 3.58, 0.0, 96.56, 0.0, 17067.28, 21.46, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 83175.84, 136.55, 27.13, 1.37, 49.49, 0.21, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.94, 224.44, 0.57, 89.26, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.43, 0.0, 521.33, -1.0, -1.0, 0.0, 13.33, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAGMM分类器结果:(阈值为 8.989, 超过阈值视为正常流量)\n",
      "原恶意样本 [-5.3201056]、DeepFool生成恶意对抗样本 [14.917352]、JSMA生成恶意对抗样本 [22.228298]、GAN训练生成恶意对抗样本 [21.5451]\n"
     ]
    }
   ],
   "source": [
    "#从上文可以看出，阈值是13.284。而生成对抗样本越过了阈值，变为了正类。\n",
    "se_pred = model.predict([se])\n",
    "deepfool_ae_pred = model.predict([deepfool_ae])\n",
    "jsmas_ae_pred = model.predict([jsmas_ae])\n",
    "gan_ae_pred = model.predict([gan_ae])\n",
    "\n",
    "print('DAGMM分类器结果:(阈值为 %.3f, 超过阈值视为正常流量)' % (anomaly_energy_threshold))\n",
    "# print(se_pred,deepfool_ae_pred,jsmas_ae_pred,gan_ae_pred)\n",
    "print('原恶意样本 %s、DeepFool生成恶意对抗样本 %s、JSMA生成恶意对抗样本 %s、GAN训练生成恶意对抗样本 %s' % (se_pred,deepfool_ae_pred,jsmas_ae_pred,gan_ae_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "[13.003081  13.116829  13.120704  13.12457   13.131608  13.095785\n",
      " 13.031114  13.1552305 13.134641  13.073575  13.0170965 13.103628\n",
      " 13.144381  13.098549  13.077541  13.035868  13.1006155 13.131209\n",
      " 13.040616  13.106663  13.134786  13.093657  13.102045  13.085722\n",
      " 13.084902  13.106194  13.093969  13.115697  13.031781  13.340057\n",
      " 13.099696  13.119233  13.154044  13.12309   13.107837  13.111301\n",
      " 13.103506  13.081823  13.127545  13.086446  13.080645  13.083693\n",
      " 13.102724  13.128983  13.011786  13.098311  13.043823  13.119553\n",
      " 13.065891  13.131181  13.1132965 13.094242  12.9655285 13.069887\n",
      " 13.0815    13.14597   13.046418  13.103576  13.108398  13.116695\n",
      " 13.110867  13.090963  13.135449  13.152494  13.082224  13.0915365\n",
      " 13.090788  13.102898  13.085703  13.1539545 13.016435  13.11187\n",
      " 13.133017  13.111604  13.019829  13.070192  13.144799  13.132201\n",
      " 13.08416   13.137001  13.097878  13.126645  13.119916  13.038234\n",
      " 13.149957  13.148299  13.096014  13.140618  13.147709  13.0873165\n",
      " 13.110411  13.158265  13.134417  13.138209  13.145137  13.075716\n",
      " 13.129773  13.107389  13.10437   13.097282 ]\n",
      "平均欺骗率：100.00%\n"
     ]
    }
   ],
   "source": [
    "ae_list = np.load('.\\wpgan-gp_1b.npy')\n",
    "\n",
    "\n",
    "def Avg_predict_rate(ae_list):\n",
    "    lens = len(ae_list)\n",
    "    print(lens)\n",
    "    ae_list = np.reshape(ae_list, [lens, 78])\n",
    "    ae_pred = model.predict(ae_list)\n",
    "    print(ae_pred)\n",
    "    \n",
    "    avarage = 0\n",
    "    for i in ae_pred:\n",
    "        if i > anomaly_energy_threshold:\n",
    "            avarage += 1\n",
    "    \n",
    "    rate = avarage / lens\n",
    "    print(\"平均欺骗率：{:.2%}\".format(rate))\n",
    "\n",
    "Avg_predict_rate(ae_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
