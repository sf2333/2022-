{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用GAN生成MNIST-demo\n",
    "\n",
    "本篇代码将使用GAN来学习MNIST数据集的生成，仅仅作为一个demo演示，后面会更新更加复杂的GAN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\DH\\AppData\\Local\\Temp/ipykernel_11344/1828024491.py:10: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /Users/Nelson/Desktop/Computer/zhihu/denoise_auto_encoder/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /Users/Nelson/Desktop/Computer/zhihu/denoise_auto_encoder/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/Nelson/Desktop/Computer/zhihu/denoise_auto_encoder/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/Nelson/Desktop/Computer/zhihu/denoise_auto_encoder/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# image load\n",
    "from tflearn.data_utils import image_preloader\n",
    "from tflearn.data_preprocessing import ImagePreprocessing\n",
    "from tflearn.data_augmentation import ImageAugmentation\n",
    "\n",
    "train_dataset_file = './train1.txt'\n",
    "test_dataset_file = './test1.txt'\n",
    "mnist = input_data.read_data_sets('/Users/Nelson/Desktop/Computer/zhihu/denoise_auto_encoder/MNIST_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d6cbfee888>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = mnist.train.images[50]\n",
    "plt.imshow(img.reshape((28, 28)), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建模型\n",
    "\n",
    "- inputs\n",
    "- generator\n",
    "- descriminator\n",
    "- loss && optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(real_size, noise_size):\n",
    "    \"\"\"\n",
    "    真实图像tensor与噪声图像tensor\n",
    "    \"\"\"\n",
    "    real_img = tf.placeholder(tf.float32, [None, real_size], name='real_img')\n",
    "    noise_img = tf.placeholder(tf.float32, [None, noise_size], name='noise_img')\n",
    "    \n",
    "    return real_img, noise_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(noise_img, n_units, out_dim, reuse=False, alpha=0.01):\n",
    "    \"\"\"\n",
    "    生成器\n",
    "    \n",
    "    noise_img: 生成器的输入\n",
    "    n_units: 隐层单元个数\n",
    "    out_dim: 生成器输出tensor的size，这里应该为32*32=784\n",
    "    alpha: leaky ReLU系数\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(\"generator\", reuse=reuse):\n",
    "        # hidden layer\n",
    "        hidden1 = tf.layers.dense(noise_img, n_units)\n",
    "        # leaky ReLU\n",
    "        hidden1 = tf.maximum(alpha * hidden1, hidden1)\n",
    "        # dropout\n",
    "        hidden1 = tf.layers.dropout(hidden1, rate=0.2)\n",
    "\n",
    "        # logits & outputs\n",
    "        logits = tf.layers.dense(hidden1, out_dim)\n",
    "        outputs = tf.tanh(logits)\n",
    "        \n",
    "        return logits, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator(img, n_units, reuse=False, alpha=0.01):\n",
    "    \"\"\"\n",
    "    判别器\n",
    "    \n",
    "    n_units: 隐层结点数量\n",
    "    alpha: Leaky ReLU系数\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"discriminator\", reuse=reuse):\n",
    "        # hidden layer\n",
    "        hidden1 = tf.layers.dense(img, n_units)\n",
    "        hidden1 = tf.maximum(alpha * hidden1, hidden1)\n",
    "        \n",
    "        # logits & outputs\n",
    "        logits = tf.layers.dense(hidden1, 1)\n",
    "        outputs = tf.sigmoid(logits)\n",
    "        \n",
    "        return logits, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "# 定义参数\n",
    "# 真实图像的size\n",
    "img_size = mnist.train.images[0].shape[0]\n",
    "print(img_size)\n",
    "# 传入给generator的噪声size\n",
    "noise_size = 100\n",
    "# 生成器隐层参数\n",
    "g_units = 128\n",
    "# 判别器隐层参数\n",
    "d_units = 128\n",
    "# leaky ReLU的参数\n",
    "alpha = 0.01\n",
    "# learning_rate\n",
    "learning_rate = 0.001\n",
    "# label smoothing\n",
    "smooth = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DH\\AppData\\Local\\Temp/ipykernel_11344/596493764.py:1: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\DH\\AppData\\Local\\Temp/ipykernel_11344/67545193.py:5: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\DH\\AppData\\Local\\Temp/ipykernel_11344/4209739237.py:10: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\DH\\AppData\\Local\\Temp/ipykernel_11344/4209739237.py:12: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\DH\\AppData\\Local\\Temp/ipykernel_11344/4209739237.py:16: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "real_img, noise_img = get_inputs(img_size, noise_size)\n",
    "\n",
    "# generator\n",
    "g_logits, g_outputs = get_generator(noise_img, g_units, img_size)\n",
    "\n",
    "# discriminator\n",
    "d_logits_real, d_outputs_real = get_discriminator(real_img, d_units)\n",
    "d_logits_fake, d_outputs_fake = get_discriminator(g_outputs, d_units, reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss\n",
    "\n",
    "这里简单说一下Loss的计算方式，由于我们上面构建了两个神经网络：generator和discriminator，因此需要分别计算loss。\n",
    "\n",
    "- discriminator\n",
    "discriminator的目的在于对于给定的真图片，识别为真（1），对于generator生成的图片，识别为假（0），因此它的loss包含了真实图片的loss和生成器图片的loss两部分。\n",
    "\n",
    "- generator\n",
    "generator的目的在于让discriminator识别不出它的图片是假的，如果用1代表真，0代表假，那么generator生成的图片经过discriminator后要输出为1，因为generator想要骗过discriminator。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\ANACONDA\\envs\\python374\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# discriminator的loss\n",
    "# 识别真实图片\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, \n",
    "                                                                     labels=tf.ones_like(d_logits_real)) * (1 - smooth))\n",
    "# 识别生成的图片\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, \n",
    "                                                                     labels=tf.zeros_like(d_logits_fake)))\n",
    "# 总体loss\n",
    "d_loss = tf.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "# generator的loss\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
    "                                                                labels=tf.ones_like(d_logits_fake)) * (1 - smooth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "\n",
    "由于我们在GAN里面一共训练了两个网络，所以需要分别定义优化函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DH\\AppData\\Local\\Temp/ipykernel_11344/1322377286.py:1: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\DH\\AppData\\Local\\Temp/ipykernel_11344/1322377286.py:9: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_vars = tf.trainable_variables()\n",
    "\n",
    "# generator中的tensor\n",
    "g_vars = [var for var in train_vars if var.name.startswith(\"generator\")]\n",
    "# discriminator中的tensor\n",
    "d_vars = [var for var in train_vars if var.name.startswith(\"discriminator\")]\n",
    "\n",
    "# optimizer\n",
    "d_train_opt = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)\n",
    "g_train_opt = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([8, 3, 9, 6, 4, 3, 0, 8, 3, 7, 2, 5, 6, 2, 1, 5, 6, 2, 4, 8, 9, 5,\n",
      "       6, 9, 7, 3, 6, 2, 8, 4, 7, 6, 6, 5, 5, 1, 2, 2, 1, 7, 5, 7, 3, 3,\n",
      "       9, 9, 4, 3, 1, 8, 1, 9, 6, 2, 2, 7, 5, 9, 6, 6, 1, 6, 9, 4],\n",
      "      dtype=uint8))\n",
      "<class 'numpy.ndarray'>\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# batch_size\n",
    "batch_size = 64\n",
    "# 训练迭代轮数\n",
    "epochs = 300\n",
    "# 抽取样本数\n",
    "n_sample = 25\n",
    "\n",
    "# 存储测试样例\n",
    "samples = []\n",
    "# 存储loss\n",
    "losses = []\n",
    "# 保存生成器变量\n",
    "saver = tf.train.Saver(var_list = g_vars)\n",
    "# 开始训练\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(epochs):\n",
    "        for batch_i in range(mnist.train.num_examples//batch_size):\n",
    "            batch = mnist.train.next_batch(batch_size)\n",
    "\n",
    "# batch = mnist.train.next_batch(batch_size)\n",
    "# print(type(batch))\n",
    "# print(batch)\n",
    "# print(type(batch[0]))\n",
    "# print(batch[0])        \n",
    "\n",
    "            batch_images = batch[0].reshape((batch_size, 784))\n",
    "            # 对图像像素进行scale，这是因为tanh输出的结果介于(-1,1),real和fake图片共享discriminator的参数\n",
    "            batch_images = batch_images*2 - 1\n",
    "            \n",
    "            # generator的输入噪声\n",
    "            batch_noise = np.random.uniform(-1, 1, size=(batch_size, noise_size))\n",
    "            \n",
    "            # Run optimizers\n",
    "            _ = sess.run(d_train_opt, feed_dict={real_img: batch_images, noise_img: batch_noise})\n",
    "            _ = sess.run(g_train_opt, feed_dict={noise_img: batch_noise})\n",
    "        \n",
    "        # 每一轮结束计算loss\n",
    "        train_loss_d = sess.run(d_loss, \n",
    "                                feed_dict = {real_img: batch_images, \n",
    "                                             noise_img: batch_noise})\n",
    "        # real img loss\n",
    "        train_loss_d_real = sess.run(d_loss_real, \n",
    "                                     feed_dict = {real_img: batch_images, \n",
    "                                                 noise_img: batch_noise})\n",
    "        # fake img loss\n",
    "        train_loss_d_fake = sess.run(d_loss_fake, \n",
    "                                    feed_dict = {real_img: batch_images, \n",
    "                                                 noise_img: batch_noise})\n",
    "        # generator loss\n",
    "        train_loss_g = sess.run(g_loss, \n",
    "                                feed_dict = {noise_img: batch_noise})\n",
    "        \n",
    "            \n",
    "        print(\"Epoch {}/{}...\".format(e+1, epochs),\n",
    "              \"Discriminator Loss: {:.4f}(Real: {:.4f} + Fake: {:.4f})...\".format(train_loss_d, train_loss_d_real, train_loss_d_fake),\n",
    "              \"Generator Loss: {:.4f}\".format(train_loss_g))    \n",
    "        # 记录各类loss值\n",
    "        losses.append((train_loss_d, train_loss_d_real, train_loss_d_fake, train_loss_g))\n",
    "        \n",
    "        # 抽取样本后期进行观察\n",
    "        sample_noise = np.random.uniform(-1, 1, size=(n_sample, noise_size))\n",
    "        gen_samples = sess.run(get_generator(noise_img, g_units, img_size, reuse=True),\n",
    "                               feed_dict={noise_img: sample_noise})\n",
    "        samples.append(gen_samples)\n",
    "        \n",
    "        # 存储checkpoints\n",
    "        saver.save(sess, './checkpoints/generator.ckpt')\n",
    "\n",
    "# 将sample的生成数据记录下来\n",
    "with open('train_samples.pkl', 'wb') as f:\n",
    "    pickle.dump(samples, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 绘制loss曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,7))\n",
    "losses = np.array(losses)\n",
    "plt.plot(losses.T[0], label='Discriminator Total Loss')\n",
    "plt.plot(losses.T[1], label='Discriminator Real Loss')\n",
    "plt.plot(losses.T[2], label='Discriminator Fake Loss')\n",
    "plt.plot(losses.T[3], label='Generator')\n",
    "plt.title(\"Training Losses\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 显示图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load samples from generator taken while training\n",
    "with open('train_samples.pkl', 'rb') as f:\n",
    "    samples = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_samples(epoch, samples):\n",
    "    \"\"\"\n",
    "    epoch代表第几次迭代的图像\n",
    "    samples为我们的采样结果\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(figsize=(7,7), nrows=5, ncols=5, sharey=True, sharex=True)\n",
    "    for ax, img in zip(axes.flatten(), samples[epoch][1]): # 这里samples[epoch][1]代表生成的图像结果，而[0]代表对应的logits\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        im = ax.imshow(img.reshape((28,28)), cmap='Greys_r')\n",
    "    \n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = view_samples(-1, samples) # 显示最后一轮的outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 显示整个生成过程图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定要查看的轮次\n",
    "epoch_idx = [0, 5, 10, 20, 40, 60, 80, 100, 150, 250] # 一共300轮，不要越界\n",
    "show_imgs = []\n",
    "for i in epoch_idx:\n",
    "    show_imgs.append(samples[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定图片形状\n",
    "rows, cols = 10, 25\n",
    "fig, axes = plt.subplots(figsize=(30,12), nrows=rows, ncols=cols, sharex=True, sharey=True)\n",
    "\n",
    "idx = range(0, epochs, int(epochs/rows))\n",
    "\n",
    "for sample, ax_row in zip(show_imgs, axes):\n",
    "    for img, ax in zip(sample[::int(len(sample)/cols)], ax_row):\n",
    "        ax.imshow(img.reshape((28,28)), cmap='Greys_r')\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成新的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载我们的生成器变量\n",
    "saver = tf.train.Saver(var_list=g_vars)\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    sample_noise = np.random.uniform(-1, 1, size=(25, noise_size))\n",
    "    gen_samples = sess.run(get_generator(noise_img, g_units, img_size, reuse=True),\n",
    "                           feed_dict={noise_img: sample_noise})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = view_samples(0, [gen_samples])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}